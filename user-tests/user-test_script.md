# Test Protocole
This protocole aim to measure different parameters, objectives and sub-objectives to define the potential of usability by new users.
First, it will measure the efficiency and reliability of our prototype for remote desktop control.
Then, the test will switch on qualitatives questions in order to be explicit using words, feelings,about how our prototype is embedded in normal behaviors.

## Objectives (Return On Investment)
> What's ROI ? See the [Interaction Design Foundation's article](https://www.interaction-design.org/literature/topics/return-on-investment)

|   KPI   |     GOALS      |    METRIC(s)   |   SIGNALs     |
|---------|----------------|----------------|---------------|
|   Task-success average |  Determine system accuracy   |   Time spent, success, help needed    |   Performing correct gesture and get feedback 
|   Adoption    |   Determine affordance    |   Verbalization, success, SUS test  | Describing gesture to do, comparison rate between imaginated one and given one   
|   Task-success | Understand every gestures | Verbalization, Usability scale  | Performing correct gestures
|   Task-success | Understand context-specific interactions | Task success, verbalization, help needed | Performing correct gestures
|   Adoption    |   Understand advantages of remote control | Usability scale, Verbalization | Conversion rate (between normal action & prototype gestures)
|   Adoption    |   Enable more flexible interpersonal relations    | Usability scale, Verbalization, Time spent    | Conversion rate


## Introduction

> This is a first survey to fix your possible experiences with some remote desktop controllers.

1. Surname, Name
2. Work Field
3. Do you keep your phone close to you when you work on your computer ?
4. Have you already experienced some gestures with your phone ? Enabling a feature without intreacting with the screen ?
5. How much do you interact with you phone when using your computer? 
6. Have you already used a presentation controller ? (Kinda a TV command for PC)
7. Did you use any phone companion for your OS ? (eg. KDE Connect for Linux or Phone Assistant on Windows or a MacOS specific).
8. If so, which features were embedded ? What did you miss when using them ?


## User Scenario

> The scenario is splitted in X parts. Before starting each part of the usability test, you would be asked how would you imagine some kind of interactions. I  Please answer as naturally as possible, any ideas that come up from your experience, will be compared with the ones you exposed to you during this part of the scenario.

> Usuability Tests will be starting. For this, a scripted narration will be followed to make you discover step by step the prototype, so you will have to face differents situations to perform actions which can be general or specific to the given context. Please, make sure to verbalize and explain as much as possible your thoughts, to describe even something that could appear useless to you or saying at loud that how to do the asked task.

### Ideal Scenario

|   Task ID     |   Task description    |   Time spent  |   Attempts    |
|---------------|-----------------------|---------------|---------------|
|       1       |   Unlock computer with the following pattern  | 00:23 | 4


### Part 1

> How would you imagine the following gestures ?
Different set of gestures are easily explained to the testers. For example:

 - Sharing content from computer
 - Getting content on computer
 - Moving forward and backward
 - Take control of the mouse
 - Share your screen with other people
 - Share your computer control to other people


### Part 2

> The testers give their feedback and different opinions on what would be the best gesture for each of the ones exposed above.
Taking that feedback, we then give them all a phone so they can try their own gesture for each of the ones proposed from the part of the team.
Each of the individual gestures from each tester was monitored and saved, and then the testers were asked to do a little explanation of their own gestures.


### Part 3

> After the testers make their own gestures following their own imagination and what would fit best according to their ideals, the team now gives them a set of orders to follow for each of the gestures mentioned. The scenario will fake a situation where two students need to work on their project and finally speech it in front of an audience.

> Sharing Gesture with your phone: One person in front of the other doing an upwards movement with your phone in hand to share a file in this case, and the receiver has to do the same or opposite movement, as he/she is receiving the file.

1. User A has to open the .xd file and make some random modifications. 
2. To user A : Your teammate need it to get some components from it. Copy and share it with him.
3. User B has to get the shared file, and open it.
4. Now you have finished to prepare your working files, you work together on a presentation and user B needs to show something on its computeer before deciding what's next. Whereas crowding at 3 around one screen, he prefers to share it with his two other teammates.
5. User A & C (faked by interviewer) have to get the screencast.
6. A needs to disconnect from the screen to go back to work on his stuff. 
7. Once choice is made, B ends the screen sharing.
8. Now your presentation is made, you are now facing your audience for your presentation. It's B's computer which is connected to the projector. A needs to access to B's computer to be able to manage the presentation.
9. Enable the screencast on your phones to check it during your speech.
10. Move in the presentation (both) and then someone ask something about your components. Your XD app window is stil opened, and you prefers to go back to it. Change window.
11. Point one component with the mouse to show what you're talking about.
12. Click on it to reveal its specifications.
13. At the end of the presentation, you offer to share the .pdf file to your audience. They can download it if they want.
14. Your presentation is finished, B needs to close access to its computer.


> Go to the next slide: As your phone is connected to the computer, do a movement with your arm moving to the right if you want to go the previous slide; do the counter movement, move your arm to the left if you want to go to the next slide. Obviously, everything with the phone in your hand.

<details>
<summary>Previous scenario</summary>
Before changing slides, the participant must follow these steps:
        1. Sync your device with the computer
        2. Get the slides or the program with it
        3. Once you have them loaded, the participant should move his arm to the right or to the left to go on to the next or to the previous slide.

 - Share your screen with other people (close distance): Turn your phone sideways (the ones the screen has been shared have to do the same movement too), then  the phone will detect the phones that are turned in this way because they are not looking in the normal direction a smartphone is hold (that is looking upfront). This movement by the sharer and the one been shared is also a confirmation, if you do not want to be shared-screen just do not hold your phone horizontally looking into X direction and being in a close distance to the screen-sharer.
 
    - For sharing in a correct way, the participants should have firstly loaded the information or the video, or whatever media they wanted to share with the people. After selecting these media, now select one piece of it to share your screen. For the part of the receivers (audience or close people), they just need to have their device unlocked and in a horizontal way (the sender also has to hold his phone this way, but after sharing screen, the sender can have the phone hold vertically), to accept the screen sharing, if it is not hold this way, it won't  receive the shared-screen, this is a method to accept it. 
 - Unlock your computer: Do a set of default movements to unlock the computer in front of you, as this should not require more than to 4 to 5 movements, they were given different figures so they can replicate them with their arm movement while having the phone.
 A computer was provided to each participant, and each of the computers had different set of movements to unlock it.

   The set of movements were the following:
   - Triangle
   - Square
   - Circle
   - An 'X'
   - A Circle and then an 'X' crossing the circle.
    After doing these movements in the adequate way, the computer should be unlocked.
</details>
 
## Part 4

> After testing all the gestures given to the testers, we asked them to complete a survey and also to compare now their own movements for each gestures to the ones given by the team. 

The team and the participants have a discussion to evaluate each gestures and the global system proposed during the test. Any remarks for improvements or about the test itself are welcomed at this step.

![gesture evaluation](./images/gesture-evaluation.jpg)

##  Debriefing

> Can you please feel the following survey about your experience during the usability test.

![test SUS](./images/test-sus.png)

### How to calculate SUS test ?
 - For odd items : ``final_score = [score] - 1``;
 - For even items : ``final_score = 5 - [score]``;
 - **Total :** ``total scores * 2.5``
Give a 0 to 100 score for each participant. We need now to make the average to have a global SUS score.

### Completing sentences about the prototype



## Analysis Results

The following example are in French, but they give an idea of how to structure data to be able to exploit them and understand it better.

### Task-Success

![task success](./images/task_success.png)

### Time Spent
Blue was a normal duration for the asked task, green a task performed quickly and a red means that the tasks takes longer than expected.

Here the first user was our reference user for the time we considered that every of him performed tasks took a normal time.

![time spent](./images/time_spent.png)

### Attempts
The following graph was counting the clics on a web product. We can adapt it to the attemps made for the needed task.

![clics](./images/clics.png)

### Journey Analysis
For this one, we have selected observables as actions (eg. waiting, pointing, filling an input, navigating...), vocal behavior (eg. asking, explanations, remarks) and the navigation status (optimal navigation, reflexion times) to highlight the difficulties in the process, common steps where users have troubles with.

![journey](./images/journey.png)

### Test SUS
A snapshot to give a non-truthful comparison with others studies conducted on famous softwares. A straight comparison would not be acceptable because tests were not conducted in same conditions, but it still gives a clear idea:

![commonSUS](./images/commonSUS.png)

### Words cloud

Highlighting some interesting sentences and keywords pronounced during the interview (jouney or questions), or from the sentences to fill. The sentences to fill aims to define a semantic field from users on the experience, given prototype, possibilities they imagine and how they feel confident when using it.
